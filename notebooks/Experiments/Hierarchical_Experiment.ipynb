{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "#--------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, time\n",
    "import datetime\n",
    "import re\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "sys.path.append('../..')\n",
    "\n",
    "# import helpers\n",
    "from src.utils import interp, get_xs, Params, get_xtv\n",
    "from src.plots import scatter_plot, line_plot\n",
    "\n",
    "\n",
    "from src.models.hierarchical_gaussian import Hierarchical_Gaussian\n",
    "from src.mcmc_diagnostics.diagnostic import MCMCDiagnostic\n",
    "from src.utils.serialize import pickle_obj, unpickle_obj, load_json, save_json\n",
    "from src.utils.params import hash_dict\n",
    "\n",
    "import torch\n",
    "import hamiltorch\n",
    "from hamiltorch import Sampler\n",
    "\n",
    "# import sampler classes\n",
    "from src.sampling_algorithms import MaskedLocalBPS, LocalBPS\n",
    "from src.sampling_algorithms.masked_bps.masked_bps_output import OutputReader\n",
    "# plot settings\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=False)\n",
    "\n",
    "import arviz as az\n",
    "from arviz.stats import ess\n",
    "\n",
    "az.style.use('arviz-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '../..'\n",
    "os.environ[\"PYTHONPATH\"] = parent_dir + \":\" + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "\n",
    "\n",
    "params_list = [Params({\n",
    "    \"rho\": rho,\n",
    "    \"refresh_rate\": refresh_rate,\n",
    "    \"num_local\": num_factors,\n",
    "    \"global_mu\": 0.,\n",
    "    \"global_prec\": 1.,\n",
    "    \"local_mu\": 0.,\n",
    "    \"local_prec\":1.,\n",
    "    'run_time': run_time,\n",
    "    'switch_prob': 0.8,\n",
    "    'num_workers': 46\n",
    "})\n",
    "               for refresh_rate in [0.1, 0.01, 0.001]\n",
    "               for rho in [0.5]\n",
    "               for run_time in [60, 90, 600, 900]\n",
    "               for num_factors in [10, 45, 100, 150]\n",
    "              ]\n",
    "    \n",
    "\n",
    "output_dir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = ['num_factors', 'iter_speed', 'ess_speed', 'sampler']\n",
    "agg_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-20 14:46:30,540\tINFO resource_spec.py:205 -- Starting Ray with 46.53 GiB memory available for workers and up to 83.82 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the dashboard at http://163.1.210.96:8080/?token=c4383e2369fb45d0383cb474f2d852d3bbe1194bae8acd6c\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray_details = ray.init(memory=5*10**10, object_store_memory = 9*10**10, include_webui=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked BPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_mask_into_groups(factor_indices, mask, num_workers = 45):\n",
    "    blocks = []\n",
    "    if mask[0] == 0:\n",
    "        if len(factor_indices) > num_workers:\n",
    "            blocks = [[] for i in np.arange(num_workers)]\n",
    "            for i in np.arange(1, len(factor_indices)):\n",
    "                blocks[i%num_workers].append(i)\n",
    "        else:\n",
    "            blocks = [[i] for i in np.arange(1, len(factor_indices))]\n",
    "    else:\n",
    "        blocks = [[i for i in np.arange(0, len(factor_indices))]]\n",
    "    return blocks\n",
    "\n",
    "def split_mask_func(factor_ind, mask):\n",
    "    return split_mask_into_groups(factor_ind, mask, num_workers = params.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run masked bps\n",
    "model_output_dir = os.path.join(output_dir, \"masked_bps\")\n",
    "\n",
    "\n",
    "if not os.path.exists(model_output_dir):\n",
    "        os.mkdir(model_output_dir)\n",
    "    \n",
    "for param_index in range(len(params_list)):\n",
    "    params = params_list[param_index]\n",
    "    param_hash = hash_dict(params.param_dict())\n",
    "    \n",
    "    ## set up output dir\n",
    "    dir_name = \"experiment_{0}\".format(param_hash)\n",
    "    dir_path = os.path.join(model_output_dir, dir_name)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    \n",
    "        # serialize params\n",
    "        param_filepath = os.path.join(dir_path, \"params.json\")\n",
    "        params.save_to_file(param_filepath)\n",
    "\n",
    "        ## Define model\n",
    "        model = Hierarchical_Gaussian(params)\n",
    "        \n",
    "        # masked sampler\n",
    "        #-----------------------------------------------------------------------------\n",
    "        init_mask = model.sample_mask(0, model.num_params)\n",
    "        sample_mask_fn = lambda : model.sample_mask(0,model.num_params)\n",
    "        \n",
    "        # Shutdown and init ray\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "\n",
    "        ray.init(memory=5*10**10, object_store_memory = 9*10**10)\n",
    "        \n",
    "\n",
    "        # init values\n",
    "        init_x = np.array([np.random.rand() for _ in range(model.num_params)])\n",
    "        init_v = np.array([np.random.rand() for _ in range(model.num_params)])\n",
    "\n",
    "        # init sampler\n",
    "        #--------------------------------------------------------------------------------------\n",
    "        mlbps = MaskedLocalBPS(init_x = init_x,\n",
    "                       init_v = init_v,\n",
    "                       init_mask = init_mask,\n",
    "                       factor_graph=model,\n",
    "                       bounce_fns=model.bounce_fns,\n",
    "                       refresh_rate=model.params.refresh_rate,\n",
    "                       split_mask_fn= split_mask_func,\n",
    "                       sample_mask_fn=sample_mask_fn,\n",
    "                       max_number_sub_samplers = params.num_workers)\n",
    "\n",
    "        # run sampler\n",
    "        print('Masked Local BPS')\n",
    "        print(params)\n",
    "        start = datetime.datetime.now()\n",
    "        print(start)\n",
    "        res = mlbps.simulate_for_time(params.run_time, output_dir=dir_path)\n",
    "        results, groups, masks = res\n",
    "        stop = datetime.datetime.now()\n",
    "        print(stop)\n",
    "        time_delta = (stop-start).seconds\n",
    "        print(\"Duration: {0}s\".format(time_delta))\n",
    "        \n",
    "        output_file = os.path.join(dir_path, \"time_delta.pickle\")\n",
    "        pickle_obj(time_delta, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = ['num_factors', 'iter_speed', 'ess_speed', 'sampler']\n",
    "agg_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check masked bps\n",
    "model_output_dir = os.path.join(output_dir, \"masked_bps\")\n",
    "masked_bps_diagnostics = []\n",
    "    \n",
    "for param_index in range(len(params_list)):\n",
    "    params = params_list[param_index]\n",
    "    param_hash = hash_dict(params.param_dict())\n",
    "\n",
    "    \n",
    "    ## set up output dir\n",
    "    dir_name = \"experiment_{0}\".format(param_hash)\n",
    "    dir_path = os.path.join(model_output_dir, dir_name)\n",
    "    if os.path.exists(dir_path):\n",
    "        print(params)\n",
    "                ## Define model\n",
    "        model = Hierarchical_Gaussian(params)\n",
    "        \n",
    "        # masked sampler\n",
    "        #-----------------------------------------------------------------------------\n",
    "        init_mask = model.sample_mask(0, model.num_params)\n",
    "        sample_mask_fn = lambda : model.sample_mask(0,model.num_params)\n",
    "        \n",
    "        # Shutdown and init ray\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "\n",
    "        ray.init(memory=5*10**10, object_store_memory = 9*10**10)\n",
    "        \n",
    "\n",
    "        # init values\n",
    "        init_x = np.array([np.random.rand() for _ in range(model.num_params)])\n",
    "        init_v = np.array([np.random.rand() for _ in range(model.num_params)])\n",
    "\n",
    "        # init sampler\n",
    "        #--------------------------------------------------------------------------------------\n",
    "        mlbps = MaskedLocalBPS(init_x = init_x,\n",
    "                       init_v = init_v,\n",
    "                       init_mask = init_mask,\n",
    "                       factor_graph=model,\n",
    "                       bounce_fns=model.bounce_fns,\n",
    "                       refresh_rate=model.params.refresh_rate,\n",
    "                       split_mask_fn= split_mask_func,\n",
    "                       sample_mask_fn=sample_mask_fn,\n",
    "                       max_number_sub_samplers = params.num_workers)\n",
    "        output_reader = OutputReader(mlbps)\n",
    "        output_file = os.path.join(dir_path, \"time_delta.pickle\")\n",
    "        time_delta = unpickle_obj(output_file)\n",
    "        output, num_iterations = output_reader.read_output(dir_path, verbose = False, inplace =False)\n",
    "\n",
    "        chains = {}\n",
    "        for i in range(mlbps.d):\n",
    "            x, v, t, mask = output[i]['x'], output[i]['v'], output[i]['t'], output[i]['mask']\n",
    "            x = np.array(x)\n",
    "            v = np.array(v)\n",
    "            t = np.array(t)\n",
    "            mask = np.array(mask)\n",
    "            nsim = len(x)\n",
    "            xs = interp(x, t, v*mask, num_intervals= nsim*12)\n",
    "            chains[\"x_{0}\".format(i)] = xs\n",
    "        mcmc_diagnostic_obj = MCMCDiagnostic(chains)\n",
    "        masked_bps_diagnostics.append(mcmc_diagnostic_obj)\n",
    "        esses = [mcmc_diagnostic_obj.ess('x_{0}'.format(i)) for i in range(mlbps.d)]\n",
    "        \n",
    "        \n",
    "        iteration_speed = num_iterations/time_delta\n",
    "        ess_speed  = np.mean(esses)/time_delta\n",
    "        agg_res.append([params.num_local, iteration_speed, ess_speed, 'masked_bps'])\n",
    "        print(params)\n",
    "        print(\"ESS /S: {0}\".format(ess_speed))\n",
    "        print(\"Iterations /S: {0}\".format(iteration_speed))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local BPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run local bps\n",
    "model_output_dir = os.path.join(output_dir, \"local_bps\")\n",
    "\n",
    "\n",
    "if not os.path.exists(model_output_dir):\n",
    "        os.mkdir(model_output_dir)\n",
    "    \n",
    "for param_index in range(len(params_list)):\n",
    "    params = params_list[param_index]\n",
    "    param_hash = hash_dict(params.param_dict())\n",
    "    \n",
    "    ## set up output dir\n",
    "    dir_name = \"experiment_{0}\".format(param_hash)\n",
    "    dir_path = os.path.join(model_output_dir, dir_name)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    \n",
    "        # serialize params\n",
    "        param_filepath = os.path.join(dir_path, \"params.json\")\n",
    "        params.save_to_file(param_filepath)\n",
    "\n",
    "        ## Define model\n",
    "        model = Hierarchical_Gaussian(params)\n",
    "        \n",
    "        \n",
    "        # init values\n",
    "        init_x = np.array([np.random.rand() for _ in range(model.num_params)])\n",
    "        init_v = np.array([np.random.rand() for _ in range(model.num_params)])\n",
    "\n",
    "        # init sampler\n",
    "        #--------------------------------------------------------------------------------------\n",
    "        lbps = LocalBPS(init_x = init_x,\n",
    "                       init_v = init_v,\n",
    "                       factor_graph=model,\n",
    "                       bounce_fns=model.bounce_fns,\n",
    "                       refresh_rate=model.params.refresh_rate)\n",
    "\n",
    "        # run sampler\n",
    "        print('Local BPS')\n",
    "        start = datetime.datetime.now()\n",
    "        print(start)\n",
    "        res = lbps.simulate_for_time(params.run_time)\n",
    "        stop = datetime.datetime.now()\n",
    "        print(stop)\n",
    "        time_delta = (stop-start).seconds\n",
    "        print(\"Duration: {0}s\".format(time_delta))\n",
    "        \n",
    "        output_file = os.path.join(dir_path, \"chains.pickle\")\n",
    "        pickle_obj(res, output_file)\n",
    "        \n",
    "        output_file = os.path.join(dir_path, \"time_delta.pickle\")\n",
    "        pickle_obj(time_delta, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check local bps\n",
    "model_output_dir = os.path.join(output_dir, \"local_bps\")\n",
    "local_bps_diagnostics = []\n",
    "    \n",
    "for param_index in range(len(params_list)):\n",
    "    params = params_list[param_index]\n",
    "    param_hash = hash_dict(params.param_dict())\n",
    "\n",
    "    \n",
    "    ## set up output dir\n",
    "    dir_name = \"experiment_{0}\".format(param_hash)\n",
    "    dir_path = os.path.join(model_output_dir, dir_name)\n",
    "    if os.path.exists(dir_path):\n",
    "        print(params)\n",
    "        output_file = os.path.join(dir_path, \"chains.pickle\")\n",
    "        res = unpickle_obj(output_file)\n",
    "\n",
    "        output_file = os.path.join(dir_path, \"time_delta.pickle\")\n",
    "        time_delta = unpickle_obj(output_file)\n",
    "\n",
    "        chains = {}\n",
    "        d = params.num_local\n",
    "        for i in range(d):\n",
    "            x1,v1,t1=get_xtv(res,i)\n",
    "            nsim = len(x1)\n",
    "            x = interp(x1,t1,v1, num_intervals=nsim*12)\n",
    "            chains[\"x_{0}\".format(i)] = x\n",
    "\n",
    "        mcmc_diagnostic_obj = MCMCDiagnostic(chains)\n",
    "        esses = [mcmc_diagnostic_obj.ess('x_{0}'.format(i)) for i in range(d)]\n",
    "        local_bps_diagnostics.append(mcmc_diagnostic_obj)\n",
    "        \n",
    "        ess_speed = np.mean(esses)/time_delta\n",
    "        iteration_speed = np.shape(res)[0]/time_delta\n",
    "        \n",
    "        agg_res.append([params.num_local, iteration_speed, ess_speed, 'local_bps'])\n",
    "        print(params)\n",
    "        print(\"ESS /S: {0}\".format(ess_speed))\n",
    "        print(\"Iterations /S: {0}\".format(iteration_speed))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "step_size = .3\n",
    "num_steps_per_sample = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run hmc \n",
    "model_output_dir = os.path.join(output_dir, \"hmc\")\n",
    "\n",
    "if not os.path.exists(model_output_dir):\n",
    "        os.mkdir(model_output_dir)\n",
    "        \n",
    "for param_index in range(len(params_list)):\n",
    "    params = params_list[param_index]\n",
    "    param_hash = hash_dict(params.param_dict())\n",
    "    \n",
    "    ## set up output dir\n",
    "    dir_name = \"experiment_{0}\".format(param_hash)\n",
    "    dir_path = os.path.join(model_output_dir, dir_name)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    \n",
    "        # serialize params\n",
    "        param_filepath = os.path.join(dir_path, \"params.json\")\n",
    "        params.save_to_file(param_filepath)\n",
    "    \n",
    "        # define model\n",
    "        rho = params.rho\n",
    "        local_prec = params.local_prec**2\n",
    "        mu = params.local_mu\n",
    "\n",
    "        prec = np.array([[local_prec, rho*local_prec], [rho*local_prec, local_prec]])\n",
    "        Sig = np.linalg.pinv(prec)\n",
    "\n",
    "        mu2 = torch.tensor(np.array([mu]))\n",
    "        mu1 = torch.tensor(np.array([mu]))\n",
    "        Sig2 = torch.tensor(np.array([[Sig[1, 1]]]))\n",
    "        Sig1 = torch.tensor(np.array([[Sig[0, 0]]]))\n",
    "        Sig21 = torch.tensor(np.array([[Sig[0, 1]]]))\n",
    "        Sig12 = Sig21.T\n",
    "\n",
    "        inv_sig2 = torch.pinverse(Sig2)\n",
    "        sig_bar = Sig1 - Sig12 * inv_sig2*Sig12.T\n",
    "        inv_sig = torch.pinverse(sig_bar)\n",
    "        transform = Sig12 *inv_sig2\n",
    "        sig_bar = Sig1 - transform * Sig21\n",
    "\n",
    "        def conditional_func(x1, x2):\n",
    "            mu_bar = mu1 + transform * (x2 - mu2)\n",
    "            stddev = torch.sqrt(sig_bar)\n",
    "            return torch.distributions.Normal(mu_bar, stddev).log_prob(x1).sum()\n",
    "\n",
    "\n",
    "        def log_prob_x0(x):\n",
    "            mean = torch.tensor(params.global_mu)\n",
    "            stddev = torch.tensor(params.global_prec)  \n",
    "\n",
    "            return torch.distributions.Normal(mean, stddev).log_prob(x).sum()\n",
    "\n",
    "        def log_prob_func(x):\n",
    "            total = log_prob_x0(x[0])\n",
    "            for i in range(len(x)-1):\n",
    "                total += conditional_func(x[i+1],x[0])\n",
    "            return total\n",
    "        \n",
    "        hamiltorch.set_random_seed(123)\n",
    "        params_init = torch.tensor(np.random.random(params.num_local))\n",
    "        \n",
    "        print('HMC')\n",
    "        start = datetime.datetime.now()\n",
    "        print(start)\n",
    "        params_hmc = hamiltorch.sample(log_prob_func=log_prob_func, \n",
    "                                       num_samples = num_samples,\n",
    "                                       params_init=params_init)\n",
    "        stop = datetime.datetime.now()\n",
    "        time_delta = (stop-start).seconds\n",
    "        numpy_chains = np.swapaxes(torch.stack(params_hmc).numpy(), 0,1)\n",
    "        \n",
    "        output_file = os.path.join(dir_path, \"chains.pickle\")\n",
    "        pickle_obj(numpy_chains, output_file)\n",
    "        \n",
    "        output_file = os.path.join(dir_path, \"time_delta.pickle\")\n",
    "        pickle_obj(time_delta, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check hmc\n",
    "model_output_dir = os.path.join(output_dir, \"hmc\")\n",
    "\n",
    "    \n",
    "for param_index in range(len(params_list)):\n",
    "    params = params_list[param_index]\n",
    "    param_hash = hash_dict(params.param_dict())\n",
    "\n",
    "    \n",
    "    ## set up output dir\n",
    "    dir_name = \"experiment_{0}\".format(param_hash)\n",
    "    dir_path = os.path.join(model_output_dir, dir_name)\n",
    "    if os.path.exists(dir_path):\n",
    "        print(params)\n",
    "        output_file = os.path.join(dir_path, \"chains.pickle\")\n",
    "        numpy_chains = unpickle_obj(output_file)\n",
    "\n",
    "        output_file = os.path.join(dir_path, \"time_delta.pickle\")\n",
    "        time_delta = unpickle_obj(output_file)\n",
    "    \n",
    "        chains = {}\n",
    "        d = np.shape(numpy_chains)[0]\n",
    "        for i in range(d):\n",
    "            chains['x_{0}'.format(i)] = numpy_chains[i]\n",
    "\n",
    "        mcmc_diagnostic_obj = MCMCDiagnostic(chains)\n",
    "        esses = [mcmc_diagnostic_obj.ess('x_{0}'.format(i)) for i in range(d)]\n",
    "        iteration_speed = np.shape(numpy_chains)[1]/time_delta\n",
    "        ess_speed  = np.mean(esses)/time_delta\n",
    "        agg_res.append([params.num_local, iteration_speed, ess_speed, 'hmc'])\n",
    "        \n",
    "        print(params)\n",
    "        print(\"ESS /S: {0}\".format(ess_speed))\n",
    "        print(\"Iterations /S: {0}\".format(iteration_speed))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(agg_res, columns = res_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">ess_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_factors</th>\n",
       "      <th>10</th>\n",
       "      <th>45</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hmc</th>\n",
       "      <td>1.830472</td>\n",
       "      <td>0.371143</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.024271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bps</th>\n",
       "      <td>38.427131</td>\n",
       "      <td>1.936605</td>\n",
       "      <td>0.476188</td>\n",
       "      <td>0.032398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masked_bps</th>\n",
       "      <td>29.529284</td>\n",
       "      <td>4.979264</td>\n",
       "      <td>0.977649</td>\n",
       "      <td>0.453831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ess_speed                              \n",
       "num_factors        10        45        100       150\n",
       "sampler                                             \n",
       "hmc           1.830472  0.371143  0.159302  0.024271\n",
       "local_bps    38.427131  1.936605  0.476188  0.032398\n",
       "masked_bps   29.529284  4.979264  0.977649  0.453831"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_plot = res_df \\\n",
    ".loc[:,['num_factors', 'sampler', 'ess_speed']] \\\n",
    ".set_index(['sampler', 'num_factors'])\\\n",
    ".unstack(1)\n",
    "\n",
    "ess_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
